{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a7f10f",
   "metadata": {},
   "source": [
    "# Binary Prediction with a Rainfall Dataset\n",
    "By Josh Houlding\n",
    "\n",
    "Competition page: [https://www.kaggle.com/competitions/playground-series-s5e3/data](https://www.kaggle.com/competitions/playground-series-s5e3/data) <br>\n",
    "Extra training data: [https://www.kaggle.com/datasets/subho117/rainfall-prediction-using-machine-learning](https://www.kaggle.com/datasets/subho117/rainfall-prediction-using-machine-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f8ed3",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87fe581c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET \n",
      " Dataset shape: (2190, 13) \n",
      " Dataset sample: \n",
      "         id  day  pressure  maxtemp  temparature  mintemp  dewpoint  humidity  \\\n",
      "289    289  290    1014.9     26.3         23.3     20.1      17.4      75.0   \n",
      "1692  1692  233    1009.5     31.0         29.8     28.2      24.5      78.0   \n",
      "1590  1590  131    1012.2     31.9         29.9     28.3      24.9      75.0   \n",
      "383    383   19    1034.6     11.2         10.4      7.0       3.4      77.0   \n",
      "1818  1818  359    1017.5     17.5         16.4     15.8      15.9      85.0   \n",
      "\n",
      "      cloud  sunshine  winddirection  windspeed  rainfall  \n",
      "289    83.0       3.0           40.0       22.0         1  \n",
      "1692   78.0       7.7          220.0       26.4         1  \n",
      "1590   72.0       8.4          180.0        8.0         1  \n",
      "383    95.0       0.0           40.0       16.0         1  \n",
      "1818   91.0       1.5           50.0       19.0         1   \n",
      "\n",
      "TEST SET \n",
      " Dataset shape: (730, 12) \n",
      " Dataset sample: \n",
      "        id  day  pressure  maxtemp  temparature  mintemp  dewpoint  humidity  \\\n",
      "468  2658  104    1012.7     29.1         26.5     25.0      24.4      89.0   \n",
      "148  2338  149    1005.7     29.4         26.7     23.1      24.7      87.0   \n",
      "302  2492  303    1017.6     28.3         25.4     23.3      20.0      84.0   \n",
      "355  2545  356    1018.5     21.0         20.9     18.4      17.3      93.0   \n",
      "515  2705  151    1008.4     34.4         30.0     27.8      24.8      72.0   \n",
      "\n",
      "     cloud  sunshine  winddirection  windspeed  \n",
      "468   83.0       3.5           70.0       26.3  \n",
      "148   84.0       0.3           20.0       14.2  \n",
      "302   88.0       1.1           60.0       14.8  \n",
      "355   88.0       0.0           50.0       14.7  \n",
      "515   22.0      11.1          230.0       25.2   \n",
      "\n",
      "Sample submission: \n",
      "        id  rainfall\n",
      "468  2658         0\n",
      "148  2338         0\n",
      "302  2492         0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data files\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "# Show samples from each data file\n",
    "print(f\"TRAINING SET \\n Dataset shape: {df_train.shape} \\n Dataset sample: \\n {df_train.sample(5, random_state=42)} \\n\")\n",
    "print(f\"TEST SET \\n Dataset shape: {df_test.shape} \\n Dataset sample: \\n {df_test.sample(5, random_state=42)} \\n\")\n",
    "print(f\"Sample submission: \\n {sample_submission.sample(3, random_state=42)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e66db",
   "metadata": {},
   "source": [
    "## Renaming column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7e6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename misspelled column\n",
    "new_column_mapping = {\"temparature\": \"temperature\"}\n",
    "df_train = df_train.rename(columns=new_column_mapping)\n",
    "df_test = df_test.rename(columns=new_column_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c70723",
   "metadata": {},
   "source": [
    "## Handling duplicates, missing values and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cada41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_test = df_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ffcb8c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value counts in training set:\n",
      " id               0\n",
      "day              0\n",
      "pressure         0\n",
      "maxtemp          0\n",
      "temperature      0\n",
      "mintemp          0\n",
      "dewpoint         0\n",
      "humidity         0\n",
      "cloud            0\n",
      "sunshine         0\n",
      "winddirection    0\n",
      "windspeed        0\n",
      "rainfall         0\n",
      "dtype: int64 \n",
      "\n",
      "Missing value counts in test set:\n",
      " id               0\n",
      "day              0\n",
      "pressure         0\n",
      "maxtemp          0\n",
      "temperature      0\n",
      "mintemp          0\n",
      "dewpoint         0\n",
      "humidity         0\n",
      "cloud            0\n",
      "sunshine         0\n",
      "winddirection    1\n",
      "windspeed        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find missing value counts per column\n",
    "print(f\"Missing value counts in training set:\\n {df_train.isna().sum()} \\n\")\n",
    "print(f\"Missing value counts in test set:\\n {df_test.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9022a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing test winddirection value with the median\n",
    "df_test[\"winddirection\"] = df_test[\"winddirection\"].fillna(df_test[\"winddirection\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5adac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values in test set after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Check missing count in test set\n",
    "print(f\"Rows with missing values in test set after imputation: {df_test.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142a3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def detect_outliers_iqr_all_cols(df, threshold=1.5):\n",
    "    \n",
    "    # Detects outliers in all numerical columns of a DataFrame using the IQR method.\n",
    "\n",
    "    #Args:\n",
    "    #    df (pd.DataFrame): The DataFrame to check.\n",
    "    #    threshold (float): The IQR multiplier (e.g., 1.5, 3).\n",
    "\n",
    "    # Returns:\n",
    "        dict: A dictionary where keys are column names and values are lists of outlier indices.\n",
    "    \n",
    "    outlier_indices = {}\n",
    "    for col in df.select_dtypes(include=np.number).columns: # Only check numerical columns\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - threshold * iqr\n",
    "        upper_bound = q3 + threshold * iqr\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index.tolist()\n",
    "        if outliers:\n",
    "            outlier_indices[col] = outliers\n",
    "    return outlier_indices\n",
    "    \"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10848176",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Find outliers in both datasets\n",
    "train_outliers = detect_outliers_iqr_all_cols(df_train)\n",
    "test_outliers = detect_outliers_iqr_all_cols(df_test)\n",
    "\n",
    "def show_outliers(outlier_df):\n",
    "    if outlier_df:\n",
    "        for col, indices in outlier_df.items():\n",
    "            print(f\"Outliers in column '{col}': {indices}\")\n",
    "    else:\n",
    "        print(\"No outliers found in any numerical columns.\")\n",
    "    \n",
    "show_outliers(train_outliers)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1e5f5",
   "metadata": {},
   "source": [
    "## Checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96104189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info for training set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2190 entries, 0 to 2189\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             2190 non-null   int64  \n",
      " 1   day            2190 non-null   int64  \n",
      " 2   pressure       2190 non-null   float64\n",
      " 3   maxtemp        2190 non-null   float64\n",
      " 4   temperature    2190 non-null   float64\n",
      " 5   mintemp        2190 non-null   float64\n",
      " 6   dewpoint       2190 non-null   float64\n",
      " 7   humidity       2190 non-null   float64\n",
      " 8   cloud          2190 non-null   float64\n",
      " 9   sunshine       2190 non-null   float64\n",
      " 10  winddirection  2190 non-null   float64\n",
      " 11  windspeed      2190 non-null   float64\n",
      " 12  rainfall       2190 non-null   int64  \n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 222.6 KB\n",
      "\n",
      "Info for test set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730 entries, 0 to 729\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             730 non-null    int64  \n",
      " 1   day            730 non-null    int64  \n",
      " 2   pressure       730 non-null    float64\n",
      " 3   maxtemp        730 non-null    float64\n",
      " 4   temperature    730 non-null    float64\n",
      " 5   mintemp        730 non-null    float64\n",
      " 6   dewpoint       730 non-null    float64\n",
      " 7   humidity       730 non-null    float64\n",
      " 8   cloud          730 non-null    float64\n",
      " 9   sunshine       730 non-null    float64\n",
      " 10  winddirection  730 non-null    float64\n",
      " 11  windspeed      730 non-null    float64\n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 68.6 KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Info for training set:\")\n",
    "df_train.info()\n",
    "print()\n",
    "\n",
    "print(f\"Info for test set:\")\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf21854",
   "metadata": {},
   "source": [
    "All data types are appropriate, and no conversions are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd37ac",
   "metadata": {},
   "source": [
    "# Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f940b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m         plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     32\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 34\u001b[0m check_feature_distributions(df_train)\n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36mcheck_feature_distributions\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_feature_distributions\u001b[39m(df):\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Checks and visualizes the distributions of numerical features in a DataFrame.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m        df (pd.DataFrame): The DataFrame to check.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     numerical_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnumber)\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numerical_cols:\n\u001b[0;32m     14\u001b[0m         plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "def check_feature_distributions(df):\n",
    "    \"\"\"\n",
    "    Checks and visualizes the distributions of numerical features in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to check.\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(df[col], bins=30)\n",
    "        plt.title(f\"Histogram of {col}\")\n",
    "\n",
    "        # Descriptive Statistics\n",
    "        plt.subplot(1, 2, 2)\n",
    "        text_str = f\"Mean: {df[col].mean():.2f}\\n\" \\\n",
    "                   f\"Median: {df[col].median():.2f}\\n\" \\\n",
    "                   f\"Std: {df[col].std():.2f}\\n\" \\\n",
    "                   f\"Skew: {stats.skew(df[col]):.2f}\\n\" \\\n",
    "                   f\"Kurtosis: {stats.kurtosis(df[col]):.2f}\"\n",
    "        plt.text(0.1, 0.5, text_str, fontsize=12)\n",
    "        plt.axis('off')  # Turn off axes for text display\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "check_feature_distributions(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bd8db",
   "metadata": {},
   "source": [
    "Most columns follow a skewed distribution, meaning standardization and normalization are sub-optimal choices. Thus, we will use the `RobustScaler` method from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5426269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show columns for ease of feature selection\n",
    "df_train.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Function to apply a RobustScaler to features\n",
    "def apply_robust_scaler(df, features_to_scale):\n",
    "    #numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "    scaler = RobustScaler()\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[features] = scaler.fit_transform(df[features])\n",
    "    return df_scaled\n",
    "\n",
    "# Define features to scale in both datasets\n",
    "features = [\"pressure\", \"maxtemp\", \"temperature\", \"mintemp\", \"dewpoint\", \"humidity\", \"cloud\", \"sunshine\", \"winddirection\",\n",
    "           \"windspeed\"]\n",
    "\n",
    "# Scale features\n",
    "df_train = apply_robust_scaler(df_train, features)\n",
    "df_test = apply_robust_scaler(df_test, features)\n",
    "\n",
    "# Show sample of both sets to check results\n",
    "print(f\"Processed training set: \\n {df_train.sample(5, random_state=42)} \\n\")\n",
    "print(f\"Processed test set: \\n {df_test.sample(5, random_state=42)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35c032",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb129d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
